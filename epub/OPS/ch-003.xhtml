<?xml version="1.0" encoding="utf-8"?>

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en" lang="en">
  <head>
    <title>3. Modifiers & Controllers</title>
    <link rel="stylesheet" type="text/css" href="css/book.css" />
  </head>

  <body>
    <section class="chapter" title="3. Modifiers & Controllers" epub:type="chapter" id="ch-003">
      <h2 class="title">3. Modifiers & Controllers</h2>

      <p>If you have stuck with me for the past two chapters, you’ll know that most natural sounds have complex harmonic structures, and that these derive from the nature of the object making the sound. You’ll also appreciate that, no matter how you play them or what you do when you record them, percussion instruments will have significantly different tones from strings, pipes, and other ‘conventional’ instruments. But this knowledge is far from sufficient to allow you to understand and create the sounds you want artificially, with a synthesizer; you also need to know about the controllers and modifiers that shape the sounds you hear. Look at it this way… if you could define a sound purely by listing all the harmonics it was composed of, manufacturers wouldn’t waste money putting all those ‘unnecessary’ filters and envelope generators and stuff in their products. So let’s move on, and find out about how you can tailor a series of synth-derived oscillations into something more musical.</p>

      <section class="sub-chapter" epub:type="division" id="ch-003-sc-001">
        <h3>Modifying a sound</h3>

        <p>There are no sounds that you can define purely in terms of their harmonic spectra. Even if a sound seems to exhibit a consistent tone and volume, there must have been a moment when it began, and a moment when it will end. This implies that the loudness of the sound is contoured in some fashion.</p>
        <p>Ignoring the start and finish for a moment, unvarying tones are called static or stationary sounds, and they are almost always musically uninteresting. Since no natural sounds are stationary over any significant timescale, the only time you are likely to encounter them is when they have been created by a signal generator (such as those found in analogue synthesizers, for example). You can think of these as devices that generate a tone by outputting a fluctuating voltage that is passed through an amplifier and then onwards to a speaker, which converts the voltage into sound that you can hear (see <a href="#fig-3-1">Figure 3.1</a>).</p>
        <p>Let’s try to make this idea a bit more meaningful. Imagine that the amplifier in <a href="#fig-3-1">Figure 3.1</a> is your hi-fi amp, and that – although the tone generator is generating a signal – the volume knob is turned fully anticlockwise so that you hear no sound. Imagine you now turn the control fully clockwise while the sound is playing, and then turn it back anticlockwise again until silence returns.</p>
        <p>If you look at <a href="#fig-3-2">Figure 3.2</a>, you will see that you have added a controller (your manipulation of the knob) that causes the amplifier to modify the audio signal presented to it. But twisting a knob every time you want a non-static sound is hardly sensible, nor are the results precisely reproducible. Moreover, it’s quite inappropriate if you are looking to use your tone generator to produce conventional sounds and notes. So you need to replace your fingers with a controller signal that gives predictable, reproducible results each time it is used. And it is this that brings us to the important concept of Voltage Control.</p>
        <p>Imagine that the Controller in <a href="#fig-3-2">Figure 3.2</a> is another fluctuating voltage of some form. This is called a Control Voltage, or CV. Don’t worry, for the moment, about how it is generated; just consider that, for any given voltage applied at the amplifier’s ‘Controller’ input, the Amplifier applies a defined Gain to the signal. This describes a Voltage Controlled Amplifier, or VCA. Now, let’s see what you can use to generate these CVs.</p>
      </section>

      <section class="sub-chapter" epub:type="division" id="ch-003-sc-002">
        <h3>Envelopes</h3>

        <p>Let’s return to the idea of modifying a sound using the volume knob on the front of a hi-fi amplifier. Let’s say that, if the knob is turned fully anticlockwise, the applied CV is 0 Volts, and the amplifier’s Gain is zero. In other words, silence reigns. At the other extreme, let’s say that, if the knob is rotated fully clockwise, the CV is 10V, and the Gain is maximum – ie. the sound is at its loudest. You could then imagine using the knob to apply varying voltages to create a loudness ‘contour’ for our sound. For example, the CV could start at 0 Volts, rise to 10V, drop to 5V, linger there for a while, before returning to 0V some time later. This profile is shown in <a href="#fig-3-3">Figure 3.3</a>.</p>
        <p>As you can see, the contour of the CV is identical to the loudness contour. In other words, you have defined the loudness of the sound at any given time using the CV. The shapes in <a href="#fig-3-3">Figure 3.3</a> are called Envelopes, so one of the devices that you can use to control our amplifier is, not surprisingly, called an Envelope Generator. EGs may be basic or complex, but (if they are not themselves modified in some way by another signal) they all share one attribute: each time they are initiated (or ‘triggered’) they provide a consistent contour, both in terms of the CVs produced and the times taken for them to change.</p>
        <p>The most famous, and for a long time the most common envelope generators, are called ADSRs. The acronym stands for Attack/Decay/Sustain/Release, and these names represent the four stages of the EG. Three of them – Attack, Decay, and Release – are measures of time, while the fourth – the Sustain – is a voltage level. (See <a href="#fig-3-4">Figure 3.4</a>.) The ADSR is, in many ways, a stroke of genius and, despite its great simplicity, it provides approximations to the contours of the sounds generated by a huge number of natural instruments.</p>
        <p>For example, imagine the sounds produced by things as different as a pipe organ, a trombone and a thunderclap. Now consider how the loudness contour of each of these can be described in terms of its A, D, S and R stages. Remember:</p>
        <ul>
          <li>The Attack time determines the speed at which the sound reaches its maximum loudness.</li>
          <li>The Decay time determines the speed at which the loudness drops until it reaches…</li>
          <li>…the Sustain Level, the level the loudness maintains until…</li>
          <li>…it decays to its final level (usually silence) in a time determined by the Release time.</li>
        </ul>
        <p>The organ has a rapid attack and maintains its full volume before dropping to silence when the player releases the key. Hence its loudness contour is almost precisely rectangular. Indeed, this shape has become so closely associated with organs that it is often referred to as an ‘organ envelope’, even when it is used in sounds that bear no relation to organ itself.</p>
        <p>By contrast, the trombone ‘speaks’ more slowly, and its loudness usually peaks at the end of the attack stage before falling back to a lower, sustained level. When the player stops blowing, the sound rapidly falls back to silence.</p>
        <p>Quiet different from either of these, the loudness of a thunderclap often develops relatively slowly, and there are no decay or sustain stages; once it has peaked, the loudness dies away slowly.</p>
        <p>As you can see from <a href="#fig-3-5">Figure 3.5</a>, these contours are fundamentally different from one another. Let’s take the trombone envelope first. This requires all four ADSR parameters, with moderate attack, decay and release times and a moderate sustain level. The organ envelope is clearly simpler, and requires just three of the ADSR envelope’s parameters, with virtually instantaneous attack and release, and a maximum sustain level. In contrast, the thunderclap only utilises two parameters. It has no Sustain or Release values (actually, this isn’t always true, but we’ll discuss that in a later part of this series).</p>
        <p>However you set the parameters of the envelope generator in your synth, if it is connected to the VCA, it has simply replaced the general term ‘controller’ in <a href="#fig-3.2">Figure 3.2</a>. Provided that you can trigger it at will, you have a device that will shape this aspect of your sound whenever you want.</p>
      </section>

      <section class="sub-chapter" epub:type="division" id="ch-003-003">
        <h3>Low frequency oscillators and tremelo</h3>

        <p>Let’s return for a moment to the concepts relating to oscillators, described in chapter 1. You will remember that every harmonic sound has a fundamental frequency that is the simplest mode of vibration of the oscillator producing it. If this fundamental lies in the range of approximately 20Hz (20 vibrations per second) to 20kHz (20,000 vibrations per second) you should hear the sound as an audible tone.</p>
        <p>Now consider again the hi-fi amplifier and its volume knob. If you swing the control from side to side once or twice per second you will introduce a new, periodic effect to the sound: that of tremolo. You are, in essence, applying an oscillator to the hi-fi’s volume. And although the frequency of this oscillator is much less than 20Hz, its effect is clearly musically important.</p>
        <p>It should come as no surprise, therefore, to find that most synthesizers have dedicated devices – Low-Frequency Oscillators (LFOs) – generating low-frequency signals that control many of the synth’s other functions. On most instruments, the LFO(s) produce oscillations in a range of frequencies lying between about 0.1Hz (one cycle every ten seconds) and 20Hz. These are suitable for producing relatively simple sonic effects, and as you can see in <a href="#fig-3-7">Figure 3.7</a>, tremolo is just a more specific example of the setup shown <a href="#fig-3-6">Figure 3.6</a>: in this case, it’s an LFO rather than an EG controlling the gain of the amplifier.</p>
        <p>Trivial though <a href="#fig-3.7">Figure 3.7</a> may be to most readers, it also demonstrates the three types of modules present in all synthesizers. In this configuration:</p>
        <ul>
          <li>The Tone Generator is a <em>Signal Generator</em> – it produces the basic audio tone;</li>
          <li>The Voltage Controlled Amplifier is an example of a <em>Modifier</em> – it changes the audio signal in some way;</li>
          <li>The LFO Sinewave generator is acting as a <em>Controller</em> – it is directing the signal-modifying action of the Modifier itself.</li>
        </ul>
        <p>But simple as this example is, you can use this architecture to produce some extremely complex sounds. You just need to change one detail in the setup…</p>
        <p>The LFOs on more powerful synths are often capable of producing higher-frequency oscillations that stray well into the audio range. Furthermore, these LFOs often offer a wide range of waveforms. But if you can modulate a signal with an audio-frequency LFO, why can’t you use another Tone Generator to do so? Of course, there’s no reason why you shouldn’t, and the architecture in <a href="#fig-3-8">Figure 3.8</a> allows you to create the complex sounds alluded to above.</p>
      </section>

      <section class="sub-chapter" epub:type="division" id="ch-003-004">
        <h3>…And the point is…?</h3>

        <p>Although this article has never strayed from the basics, three major concepts have been introduced: Control Voltages, Envelope Generators, and Low Frequency Oscillators. But these are not the most important lessons to learn.</p>
        <p>Look again at the diagrams in this article. In each of these the audio signal has been represented by the horizontal arrows, while controlling signals have been shown as vertical arrows. I like to think of these as (i) signals that you hear, and (ii) signals that control what you hear. Obvious, huh? But on the other hand, you must also recognise that in voltage terms, there is actually no difference between these signals. Consequently, many synth modules can act equally as signal generators, modifiers, and controllers, depending only upon where they are placed (and how they are used) within the sound-generating architecture.</p>
        <p>In other words: an analogue synth uses fluctuating voltage to represent audio signals and other fluctuating voltages to shape and control them. But it’s not a signal’s source that is important, it’s the destination that determines whether it is best viewed as an audio signal or a controller.</p>
        <p>And that is one of the most important synth secrets of them all.</p>
      </section>

      <figure id="fig-3-1">
        <img src="images/fig-3-1.png" />
        <figcaption>Fig. 3.1</figcaption>
      </figure>
      <figure id="fig-3-2">
        <img src="images/fig-3-2.png" />
        <figcaption>Fig. 3.2</figcaption>
      </figure>
      <figure id="fig-3-3">
        <img src="images/fig-3-3.png" />
        <figcaption>Fig. 3.3</figcaption>
      </figure>
      <figure id="fig-3-4">
        <img src="images/fig-3-4.png" />
        <figcaption>Fig. 3.4</figcaption>
      </figure>
      <figure id="fig-3-5">
        <img src="images/fig-3-5.png" />
        <figcaption>Fig. 3.5</figcaption>
      </figure>
      <figure id="fig-3-6">
        <img src="images/fig-3-6.png" />
        <figcaption>Fig. 3.6</figcaption>
      </figure>
      <figure id="fig-3-7">
        <img src="images/fig-3-7.png" />
        <figcaption>Fig. 3.7</figcaption>
      </figure>
      <figure id="fig-3-8">
        <img src="images/fig-3-8.png" />
        <figcaption>Fig. 3.8</figcaption>
      </figure>
    </section>
  </body>
</html>
